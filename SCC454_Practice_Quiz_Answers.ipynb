{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Lancaster University](https://www.lancaster.ac.uk/media/lancaster-university/content-assets/images/fst/logos/SCC-Logo.svg)\n",
        "\n",
        "# SCC.454: Large Scale Platforms for AI and Data Analysis\n",
        "## Practice Quiz — Answer Key\n",
        "\n",
        "**⚠️ FOR INSTRUCTOR USE ONLY**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Section A: Python, NumPy, Pandas & Scikit-learn (30 marks)\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 1 — NumPy Array Operations [10 marks]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Q1 — ANSWERS\n",
        "import numpy as np\n",
        "\n",
        "# (a) Create matrix M, print shape and dtype [2 marks]\n",
        "M = np.array([\n",
        "    [4, 12, 7, 3],\n",
        "    [8, 5, 14, 10],\n",
        "    [6, 11, 2, 9]\n",
        "])\n",
        "\n",
        "print(\"Matrix M:\")\n",
        "print(M)\n",
        "print(f\"Shape: {M.shape}\")  # (3, 4)\n",
        "print(f\"Data type: {M.dtype}\")  # int64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (b) Extract second row, third column, element at [1,2] [2 marks]\n",
        "print(f\"Second row (index 1): {M[1]}\")\n",
        "print(f\"Third column (index 2): {M[:, 2]}\")\n",
        "print(f\"Element at [1,2]: {M[1, 2]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (c) Sum of each row, mean of each column [3 marks]\n",
        "row_sums = np.sum(M, axis=1)\n",
        "col_means = np.mean(M, axis=0)\n",
        "\n",
        "print(f\"Sum of each row: {row_sums}\")\n",
        "print(f\"Mean of each column: {col_means}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (d) Elements > 7, then replace > 7 with 0 [3 marks]\n",
        "elements_gt_7 = M[M > 7]\n",
        "print(f\"Elements greater than 7: {elements_gt_7}\")\n",
        "\n",
        "M_copy = M.copy()\n",
        "M_copy[M_copy > 7] = 0\n",
        "print(f\"Matrix with elements > 7 replaced by 0:\")\n",
        "print(M_copy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 2 — Pandas Data Manipulation [10 marks]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Q2 — ANSWERS\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# (a) Create DataFrame and print info [2 marks]\n",
        "data = {\n",
        "    'order_id': [1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008],\n",
        "    'product': ['Laptop', 'Mouse', 'Notebook', 'Keyboard', 'Pen Set', 'Monitor', 'Stapler', 'Headphones'],\n",
        "    'category': ['Electronics', 'Electronics', 'Stationery', 'Electronics', 'Stationery', 'Electronics', 'Stationery', 'Electronics'],\n",
        "    'price': [999.99, 29.99, 5.99, 79.99, 12.99, 349.99, 8.99, 149.99],\n",
        "    'quantity': [1, 3, 10, 2, 5, 1, np.nan, 2],\n",
        "    'date': ['2025-03-01', '2025-03-01', '2025-03-02', '2025-03-02', '2025-03-03', '2025-03-03', '2025-03-04', '2025-03-04']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nDataFrame Info:\")\n",
        "print(df.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (b) Fill missing quantity with median [2 marks]\n",
        "median_qty = df['quantity'].median()\n",
        "print(f\"Median quantity: {median_qty}\")\n",
        "\n",
        "df['quantity'] = df['quantity'].fillna(median_qty)\n",
        "print(\"\\nDataFrame after filling missing quantity:\")\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (c) Add total column, filter where total > 100 [3 marks]\n",
        "df['total'] = df['price'] * df['quantity']\n",
        "print(\"DataFrame with total column:\")\n",
        "print(df)\n",
        "\n",
        "print(\"\\nRows where total > 100:\")\n",
        "print(df[df['total'] > 100])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (d) Groupby category: total revenue and order count [3 marks]\n",
        "category_stats = df.groupby('category').agg(\n",
        "    total_revenue=('total', 'sum'),\n",
        "    num_orders=('order_id', 'count')\n",
        ").sort_values('total_revenue', ascending=False)\n",
        "\n",
        "print(\"Revenue and order count by category:\")\n",
        "print(category_stats)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 3 — Scikit-learn Classification [10 marks]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Q3 — ANSWERS\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Load data\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# (a) Train-test split with stratification [2 marks]\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (b) StandardScaler - fit on train, transform both [2 marks]\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)  # Fit AND transform on training\n",
        "X_test_scaled = scaler.transform(X_test)        # Only transform on test\n",
        "\n",
        "print(f\"X_train_scaled mean (should be ~0): {X_train_scaled.mean(axis=0)}\")\n",
        "print(f\"X_train_scaled std (should be ~1): {X_train_scaled.std(axis=0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (c) Train KNN with n_neighbors=3, print accuracy [3 marks]\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = knn.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"KNN Test Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (d) Confusion matrix and classification report [3 marks]\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Section B: Apache Spark — RDDs, DataFrames & SQL (35 marks)\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === SETUP: Install PySpark and Java ===\n",
        "!pip install pyspark==3.5.0 -q\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null 2>&1\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "print(\"PySpark and Java installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spark version: 4.0.2\n"
          ]
        }
      ],
      "source": [
        "# === SETUP: Create SparkSession ===\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"SCC454-Practice-Answers\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "print(f\"Spark version: {spark.version}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 4 — RDD Transformations and Actions [12 marks]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Q4 — ANSWERS\n",
        "\n",
        "# Setup\n",
        "sentences = [\n",
        "    \"Apache Spark is fast\",\n",
        "    \"Spark is used for big data\",\n",
        "    \"Big data processing is important\",\n",
        "    \"Spark and Hadoop are popular\",\n",
        "    \"Data science uses Spark\",\n",
        "]\n",
        "\n",
        "sentences_rdd = sc.parallelize(sentences, 2)\n",
        "print(f\"RDD created with {sentences_rdd.count()} sentences\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (a) Split sentences into words, count total words [3 marks]\n",
        "words_rdd = sentences_rdd.flatMap(lambda s: s.lower().split())\n",
        "all_words = words_rdd.collect()\n",
        "\n",
        "print(f\"Total number of words: {len(all_words)}\")\n",
        "print(f\"Words: {all_words}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (b) Word count using map and reduceByKey [3 marks]\n",
        "word_counts = words_rdd \\\n",
        "    .map(lambda word: (word, 1)) \\\n",
        "    .reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "print(\"Word counts:\")\n",
        "for word, count in word_counts.collect():\n",
        "    print(f\"  {word}: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (c) Top 5 most frequent words [3 marks]\n",
        "top_5 = word_counts \\\n",
        "    .sortBy(lambda x: -x[1]) \\\n",
        "    .take(5)\n",
        "\n",
        "print(\"Top 5 most frequent words:\")\n",
        "for word, count in top_5:\n",
        "    print(f\"  {word}: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (d) Words containing letter 'a' [3 marks]\n",
        "words_with_a = words_rdd.filter(lambda w: 'a' in w)\n",
        "words_with_a_list = words_with_a.distinct().collect()\n",
        "\n",
        "print(f\"Number of unique words containing 'a': {len(words_with_a_list)}\")\n",
        "print(f\"Words: {words_with_a_list}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 5 — Spark DataFrame Operations [12 marks]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grades DataFrame:\n",
            "+----------+-----+-------+-----+--------+\n",
            "|student_id| name|subject|score|semester|\n",
            "+----------+-----+-------+-----+--------+\n",
            "|      S001|Alice|  Maths|   85|    Fall|\n",
            "|      S001|Alice|Physics|   78|    Fall|\n",
            "|      S002|  Bob|  Maths|   92|    Fall|\n",
            "|      S002|  Bob|Physics|   88|    Fall|\n",
            "|      S003|Carol|  Maths|   76|    Fall|\n",
            "|      S003|Carol|Physics|   82|    Fall|\n",
            "|      S001|Alice|  Maths|   88|  Spring|\n",
            "|      S001|Alice|Physics|   84|  Spring|\n",
            "|      S002|  Bob|  Maths|   90|  Spring|\n",
            "|      S002|  Bob|Physics|   91|  Spring|\n",
            "+----------+-----+-------+-----+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Q5 — ANSWERS\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "from pyspark.sql.functions import col, when, avg, round as spark_round\n",
        "\n",
        "# Setup\n",
        "grades_data = [\n",
        "    (\"S001\", \"Alice\", \"Maths\", 85, \"Fall\"),\n",
        "    (\"S001\", \"Alice\", \"Physics\", 78, \"Fall\"),\n",
        "    (\"S002\", \"Bob\", \"Maths\", 92, \"Fall\"),\n",
        "    (\"S002\", \"Bob\", \"Physics\", 88, \"Fall\"),\n",
        "    (\"S003\", \"Carol\", \"Maths\", 76, \"Fall\"),\n",
        "    (\"S003\", \"Carol\", \"Physics\", 82, \"Fall\"),\n",
        "    (\"S001\", \"Alice\", \"Maths\", 88, \"Spring\"),\n",
        "    (\"S001\", \"Alice\", \"Physics\", 84, \"Spring\"),\n",
        "    (\"S002\", \"Bob\", \"Maths\", 90, \"Spring\"),\n",
        "    (\"S002\", \"Bob\", \"Physics\", 91, \"Spring\"),\n",
        "]\n",
        "\n",
        "grades_schema = StructType([\n",
        "    StructField(\"student_id\", StringType(), True),\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"subject\", StringType(), True),\n",
        "    StructField(\"score\", IntegerType(), True),\n",
        "    StructField(\"semester\", StringType(), True),\n",
        "])\n",
        "\n",
        "grades_df = spark.createDataFrame(grades_data, grades_schema)\n",
        "print(\"Grades DataFrame:\")\n",
        "grades_df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (a) Select columns and filter score >= 85 [3 marks]\n",
        "result_a = grades_df \\\n",
        "    .select(\"name\", \"subject\", \"score\") \\\n",
        "    .filter(col(\"score\") >= 85)\n",
        "\n",
        "print(\"Rows with score >= 85:\")\n",
        "result_a.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (b) Add grade column (A/B/C based on score) [3 marks]\n",
        "grades_with_letter = grades_df.withColumn(\n",
        "    \"grade\",\n",
        "    when(col(\"score\") >= 90, \"A\")\n",
        "    .when(col(\"score\") >= 80, \"B\")\n",
        "    .otherwise(\"C\")\n",
        ")\n",
        "\n",
        "print(\"DataFrame with grade column:\")\n",
        "grades_with_letter.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (c) Average score per student [3 marks]\n",
        "avg_per_student = grades_df \\\n",
        "    .groupBy(\"name\") \\\n",
        "    .agg(spark_round(avg(\"score\"), 2).alias(\"avg_score\")) \\\n",
        "    .orderBy(col(\"avg_score\").desc())\n",
        "\n",
        "print(\"Average score per student:\")\n",
        "avg_per_student.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (d) Average score per subject per semester [3 marks]\n",
        "avg_per_subject_semester = grades_df \\\n",
        "    .groupBy(\"semester\", \"subject\") \\\n",
        "    .agg(spark_round(avg(\"score\"), 2).alias(\"avg_score\")) \\\n",
        "    .orderBy(\"semester\", \"subject\")\n",
        "\n",
        "print(\"Average score per subject per semester:\")\n",
        "avg_per_subject_semester.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 6 — Spark SQL [11 marks]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Students with Maths score > 85:\n",
            "+-----+-----+--------+\n",
            "| name|score|semester|\n",
            "+-----+-----+--------+\n",
            "|  Bob|   92|    Fall|\n",
            "|Alice|   88|  Spring|\n",
            "|  Bob|   90|  Spring|\n",
            "+-----+-----+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Q6 — ANSWERS\n",
        "\n",
        "# Register view\n",
        "grades_df.createOrReplaceTempView(\"grades\")\n",
        "\n",
        "# (a) Students scoring above 85 in Maths [3 marks]\n",
        "result_a = spark.sql(\"\"\"\n",
        "    SELECT name, score, semester\n",
        "    FROM grades\n",
        "    WHERE subject = 'Maths' AND score > 85\n",
        "\"\"\")\n",
        "print(\"Students with Maths score > 85:\")\n",
        "result_a.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (b) Average score per subject [3 marks]\n",
        "result_b = spark.sql(\"\"\"\n",
        "    SELECT subject, ROUND(AVG(score), 2) as avg_score\n",
        "    FROM grades\n",
        "    GROUP BY subject\n",
        "\"\"\")\n",
        "print(\"Average score per subject:\")\n",
        "result_b.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Highest score per student:\n",
            "+-----+---------+\n",
            "| name|max_score|\n",
            "+-----+---------+\n",
            "|  Bob|       92|\n",
            "|Alice|       88|\n",
            "|Carol|       82|\n",
            "+-----+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# (c) Highest score per student [5 marks]\n",
        "result_c = spark.sql(\"\"\"\n",
        "    SELECT name, MAX(score) as max_score\n",
        "    FROM grades\n",
        "    GROUP BY name\n",
        "    ORDER BY max_score DESC\n",
        "\"\"\")\n",
        "print(\"Highest score per student:\")\n",
        "result_c.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Section C: Data Preprocessing & Similarity Search (35 marks)\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 7 — Text Preprocessing & Regular Expressions [12 marks]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Q7 — ANSWERS\n",
        "from pyspark.sql.functions import regexp_extract, regexp_replace, lower, col\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "# Setup\n",
        "product_data = [\n",
        "    (1, \"Product: LAPTOP-2025 | Price: $999.99 | Stock: 50\"),\n",
        "    (2, \"Product: mouse-2024 | Price: $29.50 | Stock: 200\"),\n",
        "    (3, \"Product: KEYBOARD-2025 | Price: $79.00 | Stock: 75\"),\n",
        "    (4, \"Product: Monitor-2023 | Price: $349.99 | Stock: 30\"),\n",
        "    (5, \"Product: HEADSET-2025 | Price: $149.00 | Stock: 100\"),\n",
        "]\n",
        "\n",
        "products_df = spark.createDataFrame(product_data, [\"id\", \"raw_text\"])\n",
        "print(\"Original DataFrame:\")\n",
        "products_df.show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (a) Extract product name [3 marks]\n",
        "# Pattern: Product: followed by the product name (letters, numbers, hyphens)\n",
        "df_with_name = products_df.withColumn(\n",
        "    \"product_name\",\n",
        "    regexp_extract(col(\"raw_text\"), r\"Product:\\s*([A-Za-z0-9\\-]+)\", 1)\n",
        ")\n",
        "\n",
        "print(\"With product_name extracted:\")\n",
        "df_with_name.select(\"id\", \"product_name\").show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (b) Extract price and cast to Double [3 marks]\n",
        "df_with_price = df_with_name.withColumn(\n",
        "    \"price\",\n",
        "    regexp_extract(col(\"raw_text\"), r\"Price:\\s*\\$([0-9.]+)\", 1).cast(DoubleType())\n",
        ")\n",
        "\n",
        "print(\"With price extracted:\")\n",
        "df_with_price.select(\"id\", \"product_name\", \"price\").show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (c) Lowercase product name and remove year [3 marks]\n",
        "df_cleaned = df_with_price \\\n",
        "    .withColumn(\"product_name_lower\", lower(col(\"product_name\"))) \\\n",
        "    .withColumn(\"product_name_clean\", regexp_replace(col(\"product_name_lower\"), r\"-\\d{4}\", \"\"))\n",
        "\n",
        "print(\"With cleaned product name (lowercase, no year):\")\n",
        "df_cleaned.select(\"id\", \"product_name\", \"product_name_clean\").show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (d) Filter products from 2025 [3 marks]\n",
        "df_2025 = df_with_name.filter(col(\"product_name\").rlike(\"2025\"))\n",
        "\n",
        "print(\"Products from 2025:\")\n",
        "df_2025.select(\"id\", \"product_name\").show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 8 — Shingling & Jaccard Similarity [12 marks]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Q8 — ANSWERS\n",
        "\n",
        "# Documents\n",
        "doc_a = \"the cat sat on the mat\"\n",
        "doc_b = \"the cat sat on the hat\"\n",
        "doc_c = \"the dog ran in the park\"\n",
        "\n",
        "# (a) Word shingles function, apply with n=2 [3 marks]\n",
        "def word_shingles(text, n):\n",
        "    \"\"\"Generate word n-gram shingles from text.\"\"\"\n",
        "    words = text.lower().split()\n",
        "    shingles = set()\n",
        "    for i in range(len(words) - n + 1):\n",
        "        shingle = ' '.join(words[i:i+n])\n",
        "        shingles.add(shingle)\n",
        "    return shingles\n",
        "\n",
        "shingles_a = word_shingles(doc_a, 2)\n",
        "shingles_b = word_shingles(doc_b, 2)\n",
        "shingles_c = word_shingles(doc_c, 2)\n",
        "\n",
        "print(f\"Doc A shingles: {shingles_a}\")\n",
        "print(f\"Doc B shingles: {shingles_b}\")\n",
        "print(f\"Doc C shingles: {shingles_c}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (b) Jaccard similarity function and compute for all pairs [3 marks]\n",
        "def jaccard_similarity(set_a, set_b):\n",
        "    \"\"\"Compute Jaccard similarity between two sets.\"\"\"\n",
        "    if not set_a or not set_b:\n",
        "        return 0.0\n",
        "    intersection = len(set_a & set_b)\n",
        "    union = len(set_a | set_b)\n",
        "    return intersection / union\n",
        "\n",
        "sim_ab = jaccard_similarity(shingles_a, shingles_b)\n",
        "sim_ac = jaccard_similarity(shingles_a, shingles_c)\n",
        "sim_bc = jaccard_similarity(shingles_b, shingles_c)\n",
        "\n",
        "print(f\"Jaccard(A, B): {sim_ab:.4f}\")\n",
        "print(f\"Jaccard(A, C): {sim_ac:.4f}\")\n",
        "print(f\"Jaccard(B, C): {sim_bc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (c) Most similar and least similar pairs [2 marks]\n",
        "print(f\"Most similar pair: (A, B) with Jaccard = {sim_ab:.4f}\")\n",
        "print(f\"Least similar pair: (A, C) and (B, C) both with Jaccard = {sim_ac:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (d) Simple MinHash function and comparison [4 marks]\n",
        "def simple_minhash(shingle_set, num_hashes=50):\n",
        "    \"\"\"Compute MinHash signature using Python's hash with different salts.\"\"\"\n",
        "    signature = []\n",
        "    for i in range(num_hashes):\n",
        "        min_hash = float('inf')\n",
        "        for shingle in shingle_set:\n",
        "            # Use salt to create different hash functions\n",
        "            h = hash(f\"{i}_{shingle}\") % (2**32)\n",
        "            if h < min_hash:\n",
        "                min_hash = h\n",
        "        signature.append(min_hash)\n",
        "    return signature\n",
        "\n",
        "def estimate_jaccard_from_signatures(sig_a, sig_b):\n",
        "    \"\"\"Estimate Jaccard similarity from MinHash signatures.\"\"\"\n",
        "    matches = sum(1 for a, b in zip(sig_a, sig_b) if a == b)\n",
        "    return matches / len(sig_a)\n",
        "\n",
        "# Compute signatures\n",
        "sig_a = simple_minhash(shingles_a, num_hashes=50)\n",
        "sig_b = simple_minhash(shingles_b, num_hashes=50)\n",
        "\n",
        "# Compare\n",
        "estimated_sim = estimate_jaccard_from_signatures(sig_a, sig_b)\n",
        "true_sim = jaccard_similarity(shingles_a, shingles_b)\n",
        "\n",
        "print(f\"True Jaccard(A, B): {true_sim:.4f}\")\n",
        "print(f\"Estimated Jaccard(A, B) from MinHash: {estimated_sim:.4f}\")\n",
        "print(f\"Estimation error: {abs(true_sim - estimated_sim):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 9 — LSH with Spark ML [11 marks]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Q9 — ANSWERS\n",
        "from pyspark.ml.feature import Tokenizer, CountVectorizer, MinHashLSH\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# (a) Create DataFrame, tokenize, vectorize [3 marks]\n",
        "docs_data = [\n",
        "    (\"A\", \"the cat sat on the mat\"),\n",
        "    (\"B\", \"the cat sat on the hat\"),\n",
        "    (\"C\", \"the dog ran in the park\"),\n",
        "]\n",
        "\n",
        "docs_df = spark.createDataFrame(docs_data, [\"id\", \"text\"])\n",
        "\n",
        "# Tokenize\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "tokenized_df = tokenizer.transform(docs_df)\n",
        "\n",
        "# Vectorize with CountVectorizer (binary=True)\n",
        "cv = CountVectorizer(inputCol=\"words\", outputCol=\"features\", binary=True)\n",
        "cv_model = cv.fit(tokenized_df)\n",
        "vectorized_df = cv_model.transform(tokenized_df)\n",
        "\n",
        "print(\"Schema:\")\n",
        "vectorized_df.printSchema()\n",
        "print(\"\\nVectorized DataFrame:\")\n",
        "vectorized_df.select(\"id\", \"text\", \"features\").show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (b) Fit MinHashLSH and show hashes [3 marks]\n",
        "minhash_lsh = MinHashLSH(\n",
        "    inputCol=\"features\",\n",
        "    outputCol=\"hashes\",\n",
        "    numHashTables=3\n",
        ")\n",
        "\n",
        "lsh_model = minhash_lsh.fit(vectorized_df)\n",
        "hashed_df = lsh_model.transform(vectorized_df)\n",
        "\n",
        "print(\"DataFrame with hash values:\")\n",
        "hashed_df.select(\"id\", \"hashes\").show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (c) approxSimilarityJoin with threshold 0.6 [3 marks]\n",
        "similar_pairs = lsh_model.approxSimilarityJoin(\n",
        "    vectorized_df, vectorized_df,\n",
        "    threshold=0.6,\n",
        "    distCol=\"distance\"\n",
        ")\n",
        "\n",
        "# Filter out self-joins and duplicates\n",
        "similar_pairs_filtered = similar_pairs.filter(\n",
        "    col(\"datasetA.id\") < col(\"datasetB.id\")\n",
        ").select(\n",
        "    col(\"datasetA.id\").alias(\"id_a\"),\n",
        "    col(\"datasetB.id\").alias(\"id_b\"),\n",
        "    col(\"distance\")\n",
        ")\n",
        "\n",
        "print(\"Similar document pairs (distance < 0.6):\")\n",
        "similar_pairs_filtered.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (d) approxNearestNeighbors for document A [2 marks]\n",
        "# Get feature vector for document A\n",
        "doc_a_features = vectorized_df.filter(col(\"id\") == \"A\").select(\"features\").first()[0]\n",
        "\n",
        "# Find 2 nearest neighbors (excluding itself, so request 3)\n",
        "neighbors = lsh_model.approxNearestNeighbors(\n",
        "    vectorized_df,\n",
        "    doc_a_features,\n",
        "    numNearestNeighbors=3\n",
        ")\n",
        "\n",
        "print(\"Nearest neighbors of document A:\")\n",
        "neighbors.select(\"id\", \"text\", \"distCol\").show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Cleanup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stop Spark session\n",
        "spark.stop()\n",
        "print(\"Spark session stopped.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### End of Answer Key\n",
        "---\n",
        "*SCC.454: Large Scale Platforms for AI and Data Analysis — Lancaster University*\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
